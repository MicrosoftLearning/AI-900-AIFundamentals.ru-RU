{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Классификация изображений\r\n",
        "\r\n",
        "Когнитивная служба *Computer Vision* предоставляет полезные заранее созданные модели для работы с изображениями, но часто вам придется обучать свою собственную модель работе с компьютерным зрением. Например, предположим, что розничная компания Northwind Traders хочет создать автоматизированную систему кассы, идентифицирующую бакалейные товары, которые покупатели хотят купить, на основе изображения, сделанного камерой на кассе. Для этого необходимо подготовить классификационную модель, которая сможет классифицировать изображения, чтобы идентифицировать приобретаемый товар.\r\n",
        "\r\n",
        "![Робот, который держит планшет, классифицирующий снимки яблока, банана и апельсина.](./images/image-classification.jpg)\r\n",
        "\r\n",
        "В Azure, вы можете использовать когнитивную службу ***Пользовательское визуальное распознавание\r\n*** для обучения модели классификации изображений на основе существующих изображений. Существует два элемента для создания решения по классификации изображений. Во-первых, вы должны обучить модель распознавать различные классы, используя существующие изображения. Затем, когда модель будет обучена, вы должны опубликовать ее как услугу, которая может потребляться приложениями.\r\n",
        "\r\n",
        "## Создание ресурса пользовательского визуального распознавания\r\n",
        "\r\n",
        "Чтобы использовать службу пользовательского визуального распознавания, вам нужен ресурс Azure, который вы можете использовать для *обучения* модели, и ресурс, с помощью которого вы можете *опубликовать* ее для использования приложениями. Ресурс для одной (или обеих) задач может быть общим ресурсом **когнитивных служб Cognitive Services** или специфическим ресурсом **службы пользовательского визуального распознавания**. Вы можете использовать один и тот же ресурс Cognitive Services для каждой из этих задач, или различные ресурсы (в одном и том же регионе) для каждой задачи, чтобы управлять затратами отдельно.\r\n",
        "\r\n",
        "Используйте следующие инструкции для создания нового ресурса **пользовательского визуального распознавания**.\r\n",
        "\r\n",
        "1. В новой вкладке браузера войдите на портал Azure по адресу: [https://portal.azure.com](https://portal.azure.com), используя учетную запись Майкрософт, связанную с вашей подпиской Azure.\r\n",
        "2. Нажмите кнопку **&#65291;Создать ресурс**, выполните поиск по запросу *пользовательское визуальное распознавание* и создайте ресурс **Пользовательское визуальное распознавание** со следующими параметрами:\r\n",
        "    - **Параметры создания**: Обе\r\n",
        "    - **Подписка**: *Ваша подписка Azure*\r\n",
        "    - **Группа ресурсов**: *Выберите или создайте группу ресурсов с уникальным именем.*\r\n",
        "    - **Имя**: *Укажите уникальное имя*\r\n",
        "    - **Место проведения обучения**: *Выберите любой доступный регион*\r\n",
        "    - **Ценовая категория обучения**: классы F0\r\n",
        "    - **Расположение прогнозирования**: *Тот же регион, что и у ресурса обучения*\r\n",
        "    - **Ценовая категория прогнозирования**: классы F0\r\n",
        "\r\n",
        "    > **Примечание**: Если в вашей подписке уже есть служба пользовательского визуального распознавания F0,  выберите **S0** для этого.\r\n",
        "\r\n",
        "3. Дождитесь создания ресурсов и обратите внимание на то, что были подготовлены два ресурса пользовательского визуального распознавания: один для разработки, другой для прогнозирования. Их можно просмотреть, перейдя к группе ресурсов, в которой они были созданы.\r\n",
        "\r\n",
        "## Создайте проект службы «Пользовательское визуальное распознавание».\r\n",
        "\r\n",
        "Для обучения модели обнаружения объектов вам необходимо создать проект службы «Пользовательское визуальное распознавание» на основе вашего ресурса обучения. Для этого вы будете использовать портал «Пользовательское визуальное распознавание».\r\n",
        "\r\n",
        "1. Скачайте и извлеките обучающие изображения по адресу: https://aka.ms/fruit-images. **Примечание.** Если доступ к обучающим изображениям невозможен, в качестве временного решения перейдите на страницу https://www.github.com и затем https://aka.ms/fruit-images.  \r\n",
        "2. В другой вкладке браузера откройте портал «Пользовательское визуальное распознавание» по адресу: [https://customvision.ai](https://customvision.ai). При появлении запроса войдите в систему, используя учетную запись Microsoft, связанную с вашей подпиской Azure, и согласитесь с условиями службы.\r\n",
        "3. На портале «Пользовательское визуальное распознавание» создайте новый проект со следующими параметрами:\r\n",
        "    - **Имя**: Grocery Checkout\r\n",
        "    - **Описание**: Классификация изображений для продуктов\r\n",
        "    - **Ресурс**: *Ресурс пользовательского визуального распознавания, который вы создали ранее*\r\n",
        "    - **Типы проектов**. Классификация\r\n",
        "    - **Типы классификации**: Многоклассовая (один тег на изображение)\r\n",
        "    - **Домены**: Еда\r\n",
        "4. Нажмите **\\[+\\] Добавьте изображения** и выберите все файлы в папке **apple** («яблоко»), которые распаковали ранее. Затем загрузите файлы изображений, указав тег *apple* («яблоко»), как показано ниже:\r\n",
        "\r\n",
        "![Загрузите яблоки с тегом apple («яблоко»)](./images/upload_apples.jpg)\r\n",
        "   \r\n",
        "5. Повторите предыдущий шаг, чтобы загрузить изображения в папку **banana** с тегом *banana* («банан») и изображения в папку **orange** с тегом *orange* («апельсин»).\r\n",
        "6. Изучите изображения, которые вы загрузили в проект пользовательского визуального распознавания — в каждом классе должно быть по 15 изображений, вот так:\r\n",
        "\r\n",
        "![Помеченные изображения фруктов — 15 яблок, 15 бананов и 15 апельсинов.](./images/fruit.jpg)\r\n",
        "    \r\n",
        "7. В проекте пользовательского визуального распознавания нажмите кнопку **Обучение** над изображениями, чтобы обучить классификационную модель с помощью помеченных изображений.  Выберите параметр **Быстрое обучение**, а затем дождитесь окончания обучения итерации (это может занять около минуты).\r\n",
        "8. После обучения итерации модели просмотрите показатели производительности *Точность*, *Полнота* и *AP* — они измеряют точность прогнозирования классификационной модели, и все они должны быть высокими.\r\n",
        "\r\n",
        "## Тестирование модели\r\n",
        "\r\n",
        "Прежде чем публиковать эту итерацию модели для использования приложениями, необходимо ее протестировать.\r\n",
        "\r\n",
        "1. Нажмите кнопку **Быстрый тест** над показателями производительности.\r\n",
        "2. В поле **URL-адрес изображения** введите `https://aka.ms/apple-image` и нажмите &#10132;\r\n",
        "3. Просмотрите прогнозы, возвращаемые вашей моделью — оценка вероятности для *apple* («яблоко») должна быть самой высокой, как показано ниже:\r\n",
        "\r\n",
        "![Изображение с предсказанием класса «яблоко».](./images/test-apple.jpg)\r\n",
        "\r\n",
        "4. Закройте окно **Быстрый тест**.\r\n",
        "\r\n",
        "## Публикация и использование модели классификации изображений\r\n",
        "\r\n",
        "Теперь вы готовы опубликовать свою обученную модель и использовать ее из клиентского приложения.\r\n",
        "\r\n",
        "9. Нажмите **&#128504; Опубликовать**, чтобы опубликовать обученную модель со следующими параметрами:\r\n",
        "    - **Название модели**: groceries\r\n",
        "    - **Ресурс прогнозирования**: *Ресурс прогнозирования, который вы создали ранее*.\r\n",
        "\r\n",
        "### (!) Проверка \r\n",
        "Вы использовали то же название модели: **groceries**?   \r\n",
        "\r\n",
        "10. После публикации нажмите на значок *Настройки* (&#9881;) в правом верхнем углу страницы **Производительность**, чтобы просмотреть настройки проекта. Затем в разделе **Общие** (слева) скопируйте **идентификатор проекта**. Прокрутите вниз и вставьте его в ячейку с кодом, указанную ниже в шаге 13, заменив **YOUR_PROJECT_ID**.\r\n",
        "\r\n",
        "![Идентификатор  проекта в настройках проекта](./images/cv_project_settings.jpg)\r\n",
        "\r\n",
        "> _**Примечание**: Если в начале этого упражнения вы использовали ресурс **Cognitive Services** вместо создания ресурса **пользовательского визуального распознавания**, можно скопировать его ключ и конечную точку из правой части настроек проекта, вставить их в ячейку с кодом ниже и выполнить его, чтобы увидеть результаты. В противном случае, продолжайте выполнение описанных ниже шагов, чтобы получить ключ и конечную точку для вашего ресурса прогнозирования пользовательского визуального распознавания._\r\n",
        "\r\n",
        "11. В левом верхнем углу страницы **Настройки проекта** нажмите на значок *Галерея проектов* (&#128065;), чтобы вернуться на главную страницу портала «Пользовательское визуальное распознавание», где теперь находится ваш проект.\r\n",
        "\r\n",
        "12. На главной странице портала «Пользовательское визуальное распознавание», в правом верхнем углу, нажмите на значок *Настройки* (&#9881;), чтобы просмотреть настройки своей службы пользовательского визуального распознавания. Затем в разделе **Ресурсы** разверните свой ресурс **прогнозирования** (<u>не</u> ресурс обучения) и скопируйте его значения **Ключ** и **Конечная точка** в ячейку с кодом, указанную ниже в шаге 13, заменив **YOUR_KEY** и **YOUR_ENDPOINT**.\r\n",
        "\r\n",
        "### (!) Проверка \r\n",
        "Если вы используете ресурс **пользовательского визуального распознавания**, использовали ли вы ресурс **прогнозирования** (<u>не</u> ресурс обучения)?\r\n",
        "\r\n",
        "![Ключ и конечная точка ресурса прогнозирования в настройках службы пользовательского визуального распознавания](./images/cv_settings.jpg)\r\n",
        "\r\n",
        "13. Выполните код в расположенной ниже ячейке с кодом, нажав на кнопку **Выполнить код в ячейке** (&#9655;) (слева от ячейки), чтобы установить переменные в соответствие с идентификатором проекта, ключом и значениями конечной точки."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "project_id = 'YOUR_PROJECT_ID'\r\n",
        "cv_key = 'YOUR_KEY'\r\n",
        "cv_endpoint = 'YOUR_ENDPOINT'\r\n",
        "\r\n",
        "model_name = 'groceries' # this must match the model name you set when publishing your model iteration (it's case-sensitive)!\r\n",
        "print('Ready to predict using model {} in project {}'.format(model_name, project_id))"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599691949340
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь вы можете использовать ключ и конечную точку с клиентом службы пользовательского визуального распознавания для подключения к вашей классификационной модели пользовательского визуального распознавания.\r\n",
        "\r\n",
        "Выполните код в следующей ячейке, чтобы классифицировать подборку тестовых изображений с помощью опубликованной модели.\r\n",
        "\r\n",
        "> **Примечание**. Не стоит волноваться по поводу содержимого кода. В нем используется Computer Vision SDK для Python, чтобы получить предсказание класса для каждого изображения в папке /data/image-classification/test-fruit."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\r\n",
        "from msrest.authentication import ApiKeyCredentials\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from PIL import Image\r\n",
        "import os\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "# Get the test images from the data/vision/test folder\r\n",
        "test_folder = os.path.join('data', 'image-classification', 'test-fruit')\r\n",
        "test_images = os.listdir(test_folder)\r\n",
        "\r\n",
        "# Create an instance of the prediction service\r\n",
        "credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": cv_key})\r\n",
        "custom_vision_client = CustomVisionPredictionClient(endpoint=cv_endpoint, credentials=credentials)\r\n",
        "\r\n",
        "# Create a figure to display the results\r\n",
        "fig = plt.figure(figsize=(16, 8))\r\n",
        "\r\n",
        "# Get the images and show the predicted classes for each one\r\n",
        "print('Classifying images in {} ...'.format(test_folder))\r\n",
        "for i in range(len(test_images)):\r\n",
        "    # Open the image, and use the custom vision model to classify it\r\n",
        "    image_contents = open(os.path.join(test_folder, test_images[i]), \"rb\")\r\n",
        "    classification = custom_vision_client.classify_image(project_id, model_name, image_contents.read())\r\n",
        "    # The results include a prediction for each tag, in descending order of probability - get the first one\r\n",
        "    prediction = classification.predictions[0].tag_name\r\n",
        "    # Display the image with its predicted class\r\n",
        "    img = Image.open(os.path.join(test_folder, test_images[i]))\r\n",
        "    a=fig.add_subplot(len(test_images)/3, 3,i+1)\r\n",
        "    a.axis('off')\r\n",
        "    imgplot = plt.imshow(img)\r\n",
        "    a.set_title(prediction)\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "metadata": {
        "gather": {
          "logged": 1599692327514
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Будем надеяться, что ваша модель классификации изображений правильно определила продукты на изображениях.\r\n",
        "\r\n",
        "## Подробнее\r\n",
        "\r\n",
        "Служба пользовательского визуального распознавания предлагает больше возможностей, чем мы рассмотрели в этом упражнении. Например, вы также можете использовать службу пользовательского визуального распознавания для создания моделей *обнаружения объектов* которые не только классифицируют объекты на изображениях, но и определяет *ограничивающие прямоугольники*, показывающие расположение объекта на изображении.\r\n",
        "\r\n",
        "Подробнее о когнитивной службе «Пользовательское визуальное распознавание» см. в [документации по службе «Пользовательское визуальное распознавание»](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/home)."
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}