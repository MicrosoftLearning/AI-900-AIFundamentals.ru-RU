{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обнаружение и анализ лиц\n",
    "\n",
    "Для решений с компьютерным зрением зачастую нужно, чтобы решение с ИИ могло обнаружить, анализировать или определить человечесткие лица. Например предположим, что компания-розничный продавец «Northwind Traders» решили внедрить умный магазин, где службы ИИ следили бы за магазином, выявляли клиентов, которым нужна помощь, и направляли к ним сотрудников. Один из способов достижения этого — проведение распознавания и анализа лиц, другими словами, определение наличия лиц на изображениях, и если да, то анализ их черт.\n",
    "\n",
    "![Робот, анализирующий лицо](./images/face_analysis.jpg)\n",
    "\n",
    "## Использование когнитивной службы Face («Распознавание лиц») для обнаружения лиц\n",
    "\n",
    "Предположим, что система умных магазинов, которую хочет создать Northwind Traders, должна иметь возможность обнаруживать клиентов и анализировать черты их лиц. В Microsoft Azure для этого можно использовать **Face**, часть Azure Cognitive Services.\n",
    "\n",
    "### Создание ресурса Cognitive Services\n",
    "\n",
    "Давайте начнем с создания ресурса **Cognitive Services** в вашей подписке Azure.\n",
    "\n",
    "> **Примечание**. Если у вас уже есть ресурс Cognitive Services, просто откройте его страницу **Быстрый запуск** и скопируйте его ключ и конечную точку в ячейку ниже. В противном случае следуйте приведенным ниже действиям для создания этого ресурса.\n",
    "\n",
    "1. На другой вкладке браузера откройте портал Azure по адресу https://portal.azure.com, выполнив вход под своей учетной записью Microsoft.\n",
    "2. Нажмите кнопку **&#65291;Создать ресурс**, выполните поиск по строке *Cognitive Services* и создайте ресурс **Cognitive Services** со следующими настройками:\n",
    "    - **Подписка**. *Ваша подписка Azure*.\n",
    "    - **Группа ресурсов**. *Выберите или создайте группу ресурсов с уникальным именем*.\n",
    "    - **Регион**. *Выберите любой доступный регион:*\n",
    "    - **Имя**. *Введите уникальное имя*.\n",
    "    - **Ценовая категория**. S0\n",
    "    - **Подтверждаю, что прочитал и понял уведомления**. Выбрано.\n",
    "3. Дождитесь завершения развертывания. Затем перейдите на свой ресурс Cognitive Services и на странице **Обзор** щелкните ссылку для управления ключами службы. Для подключения к вашему ресурсу когнитивных служб из клиентских приложений вам понадобятся конечная точка и ключи.\n",
    "\n",
    "### Получение ключа и конечной точки для ресурса Cognitive Services\n",
    "\n",
    "Для использования ресурса когнитивных служб клиентским приложениям необходимы их конечная точка и ключ аутентификации:\n",
    "\n",
    "1. На портале Azure откройте страницу **Ключи и конечная точка** для вашего ресурса Cognitive Service, скопируйте **Ключ1** для вашего ресурса и вставьте его в приведенный ниже код, заменив подстановочный текст **YOUR_COG_KEY**.\n",
    "\n",
    "2. Скопируйте **конечную точку** для своего ресурса и вставьте ее в код ниже, заменив **YOUR_COG_ENDPOINT**.\n",
    "\n",
    "3. Выполните код в расположенной ниже ячейке с кодом, нажав на кнопку «Выполнить код в ячейке» <span>&#9655;</span> (в верхней левой части ячейки)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693964655
    }
   },
   "outputs": [],
   "source": [
    "cog_key = 'YOUR_COG_KEY'\n",
    "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда у вас есть ресурс Cognitive Services, можно использовать службу Face для обнаружения человеческих лиц в магазине.\n",
    "\n",
    "Чтобы увидеть пример, выполните код из ячейки ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970079
    }
   },
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from python_code import faces\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a face detection client.\n",
    "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "faces.show_faces(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждому обнаруженному лицу присваивается уникальный идентификатор, чтобы ваше приложение могло идентифицировать лица.\n",
    "\n",
    "Чтобы увидеть идентификаторы еще нескольких лиц покупателей, выполните код из ячейки ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693970447
    }
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "faces.show_faces(image_path, detected_faces, show_id=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ черт лица\n",
    "\n",
    "Face может делать гораздо больше, чем просто обнаруживать лица. Эта служба также может анализировать черты и выражения лица, чтобы предположить возраст и эмоциональное состояние. Например, выполните приведенный ниже код, чтобы проанализировать черты лица покупателя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693971321
    }
   },
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam1.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces and specified facial attributes\n",
    "attributes = ['age', 'emotion']\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
    "\n",
    "# Display the faces and attributes (code in python_code/faces.py)\n",
    "faces.show_face_attributes(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по выявленным на изображении эмоциональным баллах покупателя, покупатель, кажется, вполне доволен процессом покупок.\n",
    "\n",
    "## Поиск похожих лиц \n",
    "\n",
    "Идентификаторы лиц, созданные для каждого обнаруженного лица, используются для индивидуальной идентификации лиц. С помощью этих идентификаторов можно сравнить обнаруженное лицо с ранее обнаруженными лицами и найти лица со схожими чертами.\n",
    "\n",
    "Например, выполните код из ячейки ниже, чтобы сравнить покупателя на одном изображении с покупателями на другом и найти совпадающее лицо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693972555
    }
   },
   "outputs": [],
   "source": [
    "# Get the ID of the first face in image 1\n",
    "image_1_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_1_stream = open(image_1_path, \"rb\")\n",
    "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
    "face_1 = image_1_faces[0]\n",
    "\n",
    "# Get the face IDs in a second image\n",
    "image_2_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_2_stream = open(image_2_path, \"rb\")\n",
    "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
    "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
    "\n",
    "# Find faces in image 2 that are similar to the one in image 1\n",
    "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
    "\n",
    "# Show the face in image 1, and similar faces in image 2(code in python_code/face.py)\n",
    "faces.show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Распознавание лиц\n",
    "\n",
    "На данный момент вы видели, что Face может обнаруживать лица и черты лица и может идентифицировать два лица, похожие друг на друга. Можно пойти дальше, внедрив решение *распознавания лиц*, в котором вы обучаете Face распознавать лицо конкретного человека. Это может быть полезно в различных сценариях, например при автоматическом помечании фотографий друзей в приложении для социальных сетей или для использования распознавания лиц как части системы биометрической идентификации.\n",
    "\n",
    "Чтобы увидеть, как это работает, предположим, что компания Northwind Traders хочет использовать распознавание лиц, чтобы гарантировать, что только авторизованные сотрудники IT-отдела могут получить доступ к защищенным системам.\n",
    "\n",
    "Начнем с создания *группы лиц*, представляющих авторизованных сотрудников."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693973492
    }
   },
   "outputs": [],
   "source": [
    "group_id = 'employee_group_id'\n",
    "try:\n",
    "    # Delete group if it already exists\n",
    "    face_client.person_group.delete(group_id)\n",
    "except Exception as ex:\n",
    "    print(ex.message)\n",
    "finally:\n",
    "    face_client.person_group.create(group_id, 'employees')\n",
    "    print ('Group created!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда *группа лиц* существует, можно добавить *человека* для каждого сотрудника, которого мы хотим включить в группу, а затем зарегистрировать несколько фотографий каждого человека, чтобы служба Face могла узнать отличительные черты лица каждого человека. В идеале на фотографиях должен быть изображен один и тот же человек в разных позах и с разными выражениями лица.\n",
    "\n",
    "Мы добавим одного сотрудника по имени Уэндел и зарегистрируем три фотографии этого сотрудника."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693976898
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Add a person (Wendell) to the group\n",
    "wendell = face_client.person_group_person.create(group_id, 'Wendell')\n",
    "\n",
    "# Get photo's of Wendell\n",
    "folder = os.path.join('data', 'face', 'wendell')\n",
    "wendell_pics = os.listdir(folder)\n",
    "\n",
    "# Register the photos\n",
    "i = 0\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "for pic in wendell_pics:\n",
    "    # Add each photo to person in person group\n",
    "    img_path = os.path.join(folder, pic)\n",
    "    img_stream = open(img_path, \"rb\")\n",
    "    face_client.person_group_person.add_face_from_stream(group_id, wendell.person_id, img_stream)\n",
    "\n",
    "    # Display each image\n",
    "    img = Image.open(img_path)\n",
    "    i +=1\n",
    "    a=fig.add_subplot(1,len(wendell_pics), i)\n",
    "    a.axis('off')\n",
    "    imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавляя людей и регистрируя фотографии, мы можем обучать Face распознаванию каждого человека."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693977046
    }
   },
   "outputs": [],
   "source": [
    "face_client.person_group.train(group_id)\n",
    "print('Trained!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, когда модель обучена, ее можно использовать для идентификации распознанных лиц на изображении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1599693994820
    }
   },
   "outputs": [],
   "source": [
    "# Get the face IDs in a second image\n",
    "image_path = os.path.join('data', 'face', 'employees.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "image_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "image_face_ids = list(map(lambda face: face.face_id, image_faces))\n",
    "\n",
    "# Get recognized face names\n",
    "face_names = {}\n",
    "recognized_faces = face_client.face.identify(image_face_ids, group_id)\n",
    "for face in recognized_faces:\n",
    "    person_name = face_client.person_group_person.get(group_id, face.candidates[0].person_id).name\n",
    "    face_names[face.face_id] = person_name\n",
    "\n",
    "# show recognized faces\n",
    "faces.show_recognized_faces(image_path, image_faces, face_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дополнительные сведения\n",
    "\n",
    "Подробнее о когнитивной службе Face см. в [документации по Face](https://docs.microsoft.com/azure/cognitive-services/face/).\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}