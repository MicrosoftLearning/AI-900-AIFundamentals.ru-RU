{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Анализ текста\r\n",
        "\r\n",
        "Обработка естественного языка (Natural Language Processing, NLP) — это отрасль искусственного интеллекта (ИИ), которая имеет дело с письменным и устным языком. NLP можно использовать для создания решений, которые извлекают семантическое значение из текста или речи или формулируют осмысленные ответы на естественном языке.\r\n",
        "\r\n",
        "*Когнитивные службы* Microsoft Azure включают службу *Анализ текста*, которая предоставляет некоторые нестандартные возможности NLP, включая определение ключевых фраз в тексте, а также классификацию текста на основе тональности.\r\n",
        "\r\n",
        "![Робот читает записную книжку](./images/NLP.jpg)\r\n",
        "\r\n",
        "Предположим, вымышленная организация *Margie's Travel* побуждает клиентов подавать отзывы о пребывании в отеле. Вы можете воспользоваться службой «Анализ текста» для подведения итогов отзывов путем извлечения ключевых фраз, определения того, какие отзывы положительны, а какие отрицательны, или анализа текста отзыва на предмет упоминания известных сущностей, таких как местоположение или люди.\r\n",
        "\r\n",
        "## Просмотр документов отзывов\r\n",
        "\r\n",
        "Начнем с того, что посмотрим на некоторые отзывы об отелях, которые оставили клиенты.\r\n",
        "\r\n",
        "Отзывы находятся в текстовых файлах. Чтобы посмотреть их, просто выполните код в расположенной ниже ячейке с кодом, нажав на кнопку **Выполнить код в ячейке** (&#9655;) слева от ячейки."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Read the reviews in the /data/reviews folder\r\n",
        "reviews_folder = os.path.join('data', 'text', 'reviews')\n",
        "\n",
        "# Create a collection of reviews with id (file name) and text (contents) properties\r\n",
        "reviews = []\n",
        "for file_name in os.listdir(reviews_folder):\n",
        "    review_text = open(os.path.join(reviews_folder, file_name)).read()\n",
        "    review = {\"id\": file_name, \"text\": review_text}\n",
        "    reviews.append(review)\n",
        "\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review text\n",
        "    print('{}\\n{}\\n'.format(reviews[review_num]['id'], reviews[review_num]['text']))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694576263
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание ресурса Cognitive Services\r\n",
        "\r\n",
        "Для анализа текста в этих обзорах можно воспользоваться когнитивной службой **Анализ текста**. Для этого вам нужно предоставить ресурс службы **Анализ текста** или когнитивных служб **Cognitive Services** в вашей подписке Azure (Используйте ресурс службы «Анализ текста», если это единственная служба, которую вы планируете использовать, либо вы хотите отслеживать ее использование отдельно; в противном случае можно использовать ресурс Cognitive Services, чтобы объединить службу «Анализ текста» с другими когнитивными службами, позволяя разработчикам использовать единые конечную точку и ключ для доступа к ним).\r\n",
        "\r\n",
        "Если у вас нет такого ресурса, воспользуйтесь следующими пошаговыми инструкциями для создания ресурса **Cognitive Services** в вашей подписке Azure:\r\n",
        "\r\n",
        "> **Примечание**. Если у вас уже есть ресурс Cognitive Services, просто откройте его страницу **Быстрый запуск** и скопируйте его ключ и конечную точку в ячейку ниже. В противном случае следуйте приведенным ниже действиям для создания этого ресурса.\r\n",
        "\r\n",
        "1. На другой вкладке браузера откройте портал Azure по адресу https://portal.azure.com, выполнив вход под своей учетной записью Microsoft.\r\n",
        "2. Нажмите кнопку **&#65291;Создать ресурс**, выполните поиск по строке *Cognitive Services* и создайте ресурс **Cognitive Services** со следующими настройками:\r\n",
        "    - **Подписка**. *Ваша подписка Azure*.\r\n",
        "    - **Группа ресурсов**. *Выберите или создайте группу ресурсов с уникальным именем*.\r\n",
        "    - **Регион**. *Выберите любой доступный регион:*\r\n",
        "    - **Имя**. *Введите уникальное имя*.\r\n",
        "    - **Ценовая категория**. S0\r\n",
        "    - **Подтверждаю, что прочитал и понял уведомления**. Выбрано.\r\n",
        "3. Дождитесь завершения развертывания. Затем перейдите на свой ресурс Cognitive Services и на странице **Обзор** щелкните ссылку для управления ключами службы. Для подключения к вашему ресурсу когнитивных служб из клиентских приложений вам понадобятся конечная точка и ключи.\r\n",
        "\r\n",
        "### Получение ключа и конечной точки для ресурса Cognitive Services\r\n",
        "\r\n",
        "Для использования ресурса когнитивных служб клиентским приложениям необходимы их конечная точка и ключ аутентификации:\r\n",
        "\r\n",
        "1. На портале Azure откройте страницу **Ключи и конечная точка** для вашего ресурса Cognitive Service, скопируйте **Ключ1** для вашего ресурса и вставьте его в приведенный ниже код, заменив подстановочный текст **YOUR_COG_KEY**.\r\n",
        "2. Скопируйте **конечную точку** для своего ресурса и вставьте ее в код ниже, заменив **YOUR_COG_ENDPOINT**.\r\n",
        "3. Выполните код в расположенной ниже ячейке с кодом, нажав на зеленую кнопку <span style=\"color:green\">&#9655;</span>."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694661070
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Определение языка\r\n",
        "Начнем с определения языка, на котором написаны эти отзывы."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.cognitiveservices.language.textanalytics import TextAnalyticsClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "# Get a client for your text analytics cognitive service resource\r\n",
        "text_analytics_client = TextAnalyticsClient(endpoint=cog_endpoint,\n",
        "                                            credentials=CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Analyze the reviews you read from the /data/reviews folder earlier\r\n",
        "language_analysis = text_analytics_client.detect_language(documents=reviews)\n",
        "\n",
        "# print detected language details for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the language details for this review\n",
        "    lang = language_analysis.documents[review_num].detected_languages[0]\n",
        "    print(' - Language: {}\\n - Code: {}\\n - Score: {}\\n'.format(lang.name, lang.iso6391_name, lang.score))\n",
        "\n",
        "    # Add the detected language code to the collection of reviews (so we can do further analysis)\n",
        "    reviews[review_num][\"language\"] = lang.iso6391_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694675019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Извлечение ключевых фраз\r\n",
        "\r\n",
        "Теперь вы можете анализировать текст в отзывах клиентов для выявления ключевых фраз, которые дают некоторое представление об основных тезисах."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# # Use the client and reviews you created in the previous code cell to get key phrases\r\n",
        "key_phrase_analysis = text_analytics_client.key_phrases(documents=reviews)\n",
        "\n",
        "# print key phrases for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    # print the review id\n",
        "    print(reviews[review_num]['id'])\n",
        "\n",
        "    # Get the key phrases in this review\n",
        "    print('\\nKey Phrases:')\n",
        "    key_phrases = key_phrase_analysis.documents[review_num].key_phrases\n",
        "    # Print each key phrase\n",
        "    for key_phrase in key_phrases:\n",
        "        print('\\t', key_phrase)\n",
        "    print('\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694682067
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ключевые фразы могут помочь вам понять наиболее важные тезисы в каждом отзыве. Например, отзыв, содержащий фразу «предупредительный персонал» или «плохое обслуживание», может дать указание на некоторые из основных проблем рецензента.\r\n",
        "\r\n",
        "## Определение тональности\r\n",
        "\r\n",
        "Может быть полезно классифицировать отзывы как *положительные* или *отрицательные* на основе *оценки тональности*. И для этого можно использовать службу «Анализ текста»."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get sentiment scores\r\n",
        "sentiment_analysis = text_analytics_client.sentiment(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "\n",
        "    # Get the sentiment score for this review\n",
        "    sentiment_score = sentiment_analysis.documents[review_num].score\n",
        "\n",
        "    # classifiy 'positive' if more than 0.5, \n",
        "    if sentiment_score < 0.5:\n",
        "        sentiment = 'negative'\n",
        "    else:\n",
        "        sentiment = 'positive'\n",
        "\n",
        "    # print file name and sentiment\n",
        "    print('{} : {} ({})'.format(reviews[review_num]['id'], sentiment, sentiment_score))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694685535
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Извлечение известных сущностей\r\n",
        "\r\n",
        "*Сущности* — это вещи, которые могут быть упомянуты в тексте и относятся к каким-то общеизвестным элементам. Например, людям, местам или датам. Предположим, вас интересуют даты и места, упомянутые в отзывах, — вы можете воспользоваться следующим кодом, чтобы найти их."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the client and reviews you created previously to get named entities\r\n",
        "entity_analysis = text_analytics_client.entities(documents=reviews)\n",
        "\n",
        "# Print the results for each review\r\n",
        "for review_num in range(len(reviews)):\n",
        "    print(reviews[review_num]['id'])\n",
        "    # Get the named entitites in this review\n",
        "    entities = entity_analysis.documents[review_num].entities\n",
        "    for entity in entities:\n",
        "        # Only print datetime or location entitites\n",
        "        if entity.type in ['DateTime','Location']:\n",
        "            link = '(' + entity.wikipedia_url + ')' if entity.wikipedia_id is not None else ''\n",
        "            print(' - {}: {} {}'.format(entity.type, entity.name, link))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694688496
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обратите внимание, что некоторые объекты достаточно известны, чтобы иметь соответствующую страницу в Википедии, и в этом случае служба «Анализ текста» возвращает URL этой страницы.\r\n",
        "\r\n",
        "## Дополнительные сведения\r\n",
        "\r\n",
        "Дополнительные сведения о службе «Анализ текста» см. в [документации по службе «Анализ текста»](https://docs.microsoft.com/azure/cognitive-services/text-analytics/)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}