{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Оптическое распознавание символов\r\n",
        "\r\n",
        "![Робот читает газету](./images/ocr.jpg)\r\n",
        "\r\n",
        "Общей проблемой компьютерного зрения является обнаружение и интерпретация текста на изображении. Этот вид обработки часто называют *оптическим распознаванием символов* (optical character recognition, OCR).\r\n",
        "\r\n",
        "## Чтение текста на изображении с помощью службы Computer Vision\r\n",
        "\r\n",
        "Когнитивная служба **Computer Vision** обеспечивает поддержку OCR-задач, в том числе:\r\n",
        "\r\n",
        "- API **для OCR**, который можно использовать для чтения текста на нескольких языках. Этот API используется асинхронно и может быть использован и для печатного, и для рукописного текста.\r\n",
        "- API **для чтения**, оптимизированный для больших документов. Этот API может использоваться синхронно, и работает хорошо, когда нужно обнаружить и прочитать небольшое количество текста на изображении.\r\n",
        "\r\n",
        "Эту службу можно использовать, создав ресурс либо **Computer Vision**, либо **Cognitive Services**.\r\n",
        "\r\n",
        "Если вы еще этого не сделали, создайте ресурс **Cognitive Services** в своей подписке Azure.\r\n",
        "\r\n",
        "> **Примечание**. Если у вас уже есть ресурс Cognitive Services, просто откройте его страницу **Быстрый запуск** и скопируйте его ключ и конечную точку в ячейку ниже. В противном случае следуйте приведенным ниже действиям для создания этого ресурса.\r\n",
        "\r\n",
        "1. В другой вкладке браузера откройте портал Azure по адресу: https://portal.azure.com, войдя в систему под учетной записью Microsoft.\r\n",
        "\r\n",
        "2. Нажмите кнопку **&#65291;Создать ресурс**, выполните поиск по строке *Cognitive Services* и создайте ресурс **Cognitive Services** со следующими настройками:\r\n",
        "    - **Подписка**. *Ваша подписка Azure*.\r\n",
        "    - **Группа ресурсов**. *Выберите или создайте группу ресурсов с уникальным именем*.\r\n",
        "    - **Регион**. *Выберите любой доступный регион*:\r\n",
        "    - **Имя**. *Введите уникальное имя*.\r\n",
        "    - **Ценовая категория**. S0\r\n",
        "    - **Подтверждаю, что прочитал и понял уведомления**. Выбрано.\r\n",
        "3. Дождитесь завершения развертывания. Затем перейдите на свой ресурс Cognitive Services и на странице **Обзор** щелкните ссылку для управления ключами службы. Для подключения к вашему ресурсу когнитивных служб из клиентских приложений вам понадобятся конечная точка и ключи.\r\n",
        "\r\n",
        "### Получение ключа и конечной точки для ресурса Cognitive Services\r\n",
        "\r\n",
        "Для использования ресурса когнитивных служб клиентским приложениям необходимы их конечная точка и ключ аутентификации:\r\n",
        "\r\n",
        "1. На портале Azure откройте страницу **Ключи и конечная точка** для вашего ресурса Cognitive Service, скопируйте **Ключ1** для вашего ресурса и вставьте его в приведенный ниже код, заменив подстановочный текст **YOUR_COG_KEY**.\r\n",
        "2. Скопируйте **конечную точку** для своего ресурса и вставьте ее в код ниже, заменив **YOUR_COG_ENDPOINT**.\r\n",
        "3. Выполните код в расположенной ниже ячейке с кодом, нажав на кнопку **Выполнить код в ячейке** (&#9655;) слева от ячейки."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cog_key = 'YOUR_COG_KEY'\n",
        "cog_endpoint = 'YOUR_COG_ENDPOINT'\n",
        "\n",
        "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694246277
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь, когда вы установили ключ и конечную точку, можно использовать ресурс службы компьютерного зрения для извлечения текста из изображения.\r\n",
        "\r\n",
        "Давайте начнем с API **для OCR**, который позволит вам синхронно анализировать изображение и читать любой содержащийся в нем текст. В этом случае у вас есть рекламное изображение для вымышленной розничной компании Northwind Traders, которое содержит некоторый текст. Чтобы прочитать его, выполните код из ячейки ниже. "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'advert.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Use the Computer Vision service to find text in the image\r\n",
        "read_results = computervision_client.recognize_printed_text_in_stream(image_stream)\n",
        "\n",
        "# Process the text line by line\r\n",
        "for region in read_results.regions:\n",
        "    for line in region.lines:\n",
        "\n",
        "        # Read the words in the line of text\n",
        "        line_text = ''\n",
        "        for word in line.words:\n",
        "            line_text += word.text + ' '\n",
        "        print(line_text.rstrip())\n",
        "\n",
        "# Open image to display it.\r\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "img = Image.open(image_path)\n",
        "draw = ImageDraw.Draw(img)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694257280
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найденный на изображении текст организован в иерархическую структуру из областей, строк и слов, и код считывает их для получения результатов.\r\n",
        "\r\n",
        "В результатах можно увидеть текст, прочитанный из изображения. \r\n",
        "\r\n",
        "## Отображение ограничивающих прямоугольников\r\n",
        "\r\n",
        "Результаты также включают координаты *ограничивающих прямоугольников* для строк текста и отдельных слов, найденных на изображении. Выполните код из ячейки ниже, чтобы увидеть координаты ограничивающих прямоугольников для строк текста на рекламном изображении, который вы получили ранее."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Open image to display it.\r\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "img = Image.open(image_path)\n",
        "draw = ImageDraw.Draw(img)\n",
        "\n",
        "# Process the text line by line\r\n",
        "for region in read_results.regions:\n",
        "    for line in region.lines:\n",
        "\n",
        "        # Show the position of the line of text\n",
        "        l,t,w,h = list(map(int, line.bounding_box.split(',')))\n",
        "        draw.rectangle(((l,t), (l+w, t+h)), outline='magenta', width=5)\n",
        "\n",
        "        # Read the words in the line of text\n",
        "        line_text = ''\n",
        "        for word in line.words:\n",
        "            line_text += word.text + ' '\n",
        "        print(line_text.rstrip())\n",
        "\n",
        "# Show the image with the text locations highlighted\r\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694266106
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В результате на изображении будут показаны ограничивающие прямоугольники для каждой строки текста.\r\n",
        "\r\n",
        "## Использование API для чтения\r\n",
        "\r\n",
        "API для OCR, который вы использовали ранее, хорошо работает для изображений с небольшим количеством текста. Когда нужно прочитать большие объемы текста, например отсканированные документы, можно использовать API **для чтения**. Это требует многоступенчатого процесса:\r\n",
        "\r\n",
        "1. Представьте изображение в службу Computer Vision для асинхронного чтения и анализа.\r\n",
        "2. Дождитесь завершения операции анализа.\r\n",
        "3. Получите результаты анализа.\r\n",
        "\r\n",
        "Выполните код в следующей ячейке, чтобы использовать этот процесс для чтения текста в отсканированном письме менеджеру магазина Northwind Traders."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'letter.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Submit a request to read printed text in the image and get the operation ID\r\n",
        "read_operation = computervision_client.read_in_stream(image_stream,\n",
        "                                                      raw=True)\n",
        "operation_location = read_operation.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Wait for the asynchronous operation to complete\r\n",
        "while True:\n",
        "    read_results = computervision_client.get_read_result(operation_id)\n",
        "    if read_results.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# If the operation was successfuly, process the text line by line\r\n",
        "if read_results.status == OperationStatusCodes.succeeded:\n",
        "    for result in read_results.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# Open image to display it.\r\n",
        "print('\\n')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694312346
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Просмотрите результаты. Вот полная расшифровка письма, состоящая в основном из печатного текста с рукописной подписью. Оригинальное изображение письма отображается под результатами OCR (возможно, вам понадобится прокрутка, чтобы его увидеть).\r\n",
        "\r\n",
        "## Чтение рукописного текста\r\n",
        "\r\n",
        "В предыдущем примере в запросе на анализ изображения был задан режим распознавания текста, который оптимизировал работу с *печатным* текстом. Однако обратите внимание, что была прочитана и рукописная подпись.\r\n",
        "\r\n",
        "Такая возможность чтения рукописного текста чрезвычайно полезна. Предположим, вы написали заметку, содержащую список покупок, и хотите использовать приложение на телефоне для прочтения заметки и расшифровки содержащегося в ней текста.\r\n",
        "\r\n",
        "Выполните код из ячейки ниже, чтобы посмотреть пример операции чтения рукописного списка покупок."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import time\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "# Read the image file\r\n",
        "image_path = os.path.join('data', 'ocr', 'note.jpg')\n",
        "image_stream = open(image_path, \"rb\")\n",
        "\n",
        "# Get a client for the computer vision service\r\n",
        "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
        "\n",
        "# Submit a request to read printed text in the image and get the operation ID\r\n",
        "read_operation = computervision_client.read_in_stream(image_stream,\n",
        "                                                      raw=True)\n",
        "operation_location = read_operation.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        "\n",
        "# Wait for the asynchronous operation to complete\r\n",
        "while True:\n",
        "    read_results = computervision_client.get_read_result(operation_id)\n",
        "    if read_results.status not in [OperationStatusCodes.running]:\n",
        "        break\n",
        "    time.sleep(1)\n",
        "\n",
        "# If the operation was successfuly, process the text line by line\r\n",
        "if read_results.status == OperationStatusCodes.succeeded:\n",
        "    for result in read_results.analyze_result.read_results:\n",
        "        for line in result.lines:\n",
        "            print(line.text)\n",
        "\n",
        "# Open image to display it.\r\n",
        "print('\\n')\n",
        "fig = plt.figure(figsize=(12,12))\n",
        "img = Image.open(image_path)\n",
        "plt.axis('off')\n",
        "plt.imshow(img)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1599694340593
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Дополнительные сведения\r\n",
        "\r\n",
        "Дополнительные сведения об использовании службы Computer Vision для распознавания текста см. в [документации по Computer Vision](https://docs.microsoft.com/ru-ru/azure/cognitive-services/computer-vision/concept-recognizing-text)"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}